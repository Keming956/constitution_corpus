{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script is used to clean the data collected from the web scraping script.\n",
    "It will remove the time in the beginning of each line.\n",
    "The pair the English text and French text together.\n",
    "It will output the cleaned data to a new csvfile.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(file_path):\n",
    "    # parse the xml file and return a list of texts\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    texts = []\n",
    "    for section in root.findall(\"section\"):\n",
    "        text = section.get(\"text\")\n",
    "        # remove the time in the beginning of each line with regex\n",
    "        cleaned_text = re.sub(r\"^\\d{2}:\\d{2}\", \"\", text).strip()\n",
    "        texts.append(cleaned_text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(all_texts, output_file):\n",
    "    # write the cleaned data to a new csv file\n",
    "    with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"en_text\", \"fr_text\"])\n",
    "        for en_texts, fr_texts in all_texts:\n",
    "            for en_text, fr_text in zip(en_texts, fr_texts):\n",
    "                writer.writerow([en_text, fr_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the file paths\n",
    "en_files = sorted(glob.glob(\"english-*.xml\"))\n",
    "fr_files = sorted(glob.glob(\"french-*.xml\"))\n",
    "\n",
    "# check if the number of files are the same\n",
    "assert len(en_files) == len(fr_files), \"The number of files are not the same.\"\n",
    "\n",
    "# parse the xml files\n",
    "all_texts = []\n",
    "for en_file, fr_file in zip(en_files, fr_files):\n",
    "    en_texts = parse_xml(en_file)\n",
    "    fr_texts = parse_xml(fr_file)\n",
    "    all_texts.append((en_texts, fr_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the cleaned data to a new csv file\n",
    "output_file = \"../data/raw/subtitles_combined.csv\"\n",
    "\n",
    "write_to_csv(all_texts, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OTC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
